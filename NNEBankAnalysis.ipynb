{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bank Customer Analysis With Neural Network Engine",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDGSvBF0ntfL"
      },
      "source": [
        "*A quick note: You can run all of the code blocks below by hovering your mouse over the brackets at the top left of each block and clicking the play button that appears. In order to run a block of code, you have to have already run the subsequent blocks (In other words you have to run the code blocks in order)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZrLkFopnvMQ"
      },
      "source": [
        "# **Analyzing Data About Bank Customers Using My Own Neural Network Engine**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN7hyOOmn-Ia"
      },
      "source": [
        "In this Python notebook, I will be showcasing a more advanced and applicable use of the neural network engine that I created from scratch. This Python notebook is an adaptation of two Python notebooks that I have created in the past. I would suggest reading both of the following notebooks before continuing with the following:\n",
        "\n",
        "* [Bank Data Analysis Deep Learning](https://colab.research.google.com/drive/1stLWnNExen8nat0gEdQbnEgCeZ3UdGnO?usp=sharing)\n",
        "\n",
        "* [Neural Network Engine From Scratch](https://colab.research.google.com/drive/1lOPb-V4UYwZnURc1HNYiKn4cuzKdpRTx?usp=sharing)\n",
        "\n",
        "I will be using the neural network engine I created and explained in the second notebook which functions similarly to libraries like TensorFlow/Keras or PyTorch in order to solve the machine learning problem from the first notebook linked above.\n",
        "\n",
        "**Run the code below to load the neural network engine that is fully explained in the notebook linked above.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc8JD6IfljUT"
      },
      "source": [
        "from random import random\n",
        "#In this case we will need the exponential function from numpy because the \n",
        "#default Python exponential function can't handle the numbers in this case.\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork(object):\n",
        "    \"\"\"\n",
        "    This class will create an instance of a neural network. The idea is that we \n",
        "    will be able to use the methods in this class to customize the neural network\n",
        "    to the exact size that we want it to be (including the number of layers, number\n",
        "    of neurons per layer, and the activations of the neurons). This means that we\n",
        "    will need our forward and backpropgation algorithms to be programmed so that\n",
        "    they will function properly no matter the size of the network.\n",
        "\n",
        "    The code for this class is split into four main steps:\n",
        "    1. Initialization: In this section, we enable the creation and customization \n",
        "       of the neural network (adding layers, changing activations, etc.)\n",
        "    2. Forward Propagation: In this section, we create the forward propagation\n",
        "       algorithm which will both store the outputs of each neuron during forward\n",
        "       propagation and will return the output of the network (thus it can be used)\n",
        "       when our network is fully trained to make predictions.\n",
        "    3. Backward Propagation: In this section, we create the backward propagation\n",
        "       algorithm which calculates the errors of each neuron in the network based\n",
        "       on the error of the network calculated after forward propagation and adjusts\n",
        "       the weights of each neuron accordingly.\n",
        "    4. Training: In this section, we create the function which will enable us to\n",
        "       train our network with specific training data. This is where we will be able \n",
        "       to specify relevant learning parameters like the learning rate and number of\n",
        "       epochs that we want.\n",
        "    \"\"\"\n",
        "\n",
        "    # Section 1: Initialization \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        When we first initialize the network, we don't need to do much. All we do\n",
        "        here is create an empty list for our neural network (which can be filled)\n",
        "        in later.\n",
        "        \"\"\"\n",
        "        self.neural_network = list()\n",
        "    \n",
        "    def add_layer(self, num_neurons, activation = 'sigmoid', input_layer = False):\n",
        "        \"\"\"\n",
        "        This is the function that allows the user to add layers to the neural \n",
        "        network. They can specify the number of neurons in the layer, the activation\n",
        "        function used by the neurons in the layer (which is set by default to the\n",
        "        sigmoid function but can be adjusted), and if the layer is the input layer.\n",
        "        Note that the first layer added to the network must always be specified \n",
        "        as the input layer.\n",
        "        \"\"\"\n",
        "        if not input_layer:\n",
        "            #Each layer is represented as a list of neurons where each neuron\n",
        "            #is represented as a dictionary with a bias, a set of weights corresponding\n",
        "            #to the neurons in the previous layer, and an activation function.\n",
        "            self.neural_network.append([{'bias': random(), \n",
        "                                         'weights': [random() for i in range(self.last_layer_neurons)],\n",
        "                                         'activation': activation} \n",
        "                                         for i in range(num_neurons)])\n",
        "        self.last_layer_neurons = num_neurons\n",
        "\n",
        "    # Section 2: Forward Propagation\n",
        "    def sigmoid(self, value, derivative = False):\n",
        "        \"\"\"\n",
        "        This is the Sigmoid activation function which can be used in computing the\n",
        "        activation of a neuron. It can be also used as the derivative of the sigmoid\n",
        "        function (which you will see we need later in backpropagation).\n",
        "        \"\"\"\n",
        "        if derivative:\n",
        "            return value * (1 - value)\n",
        "        return 1/(1 + np.exp(-1 * value))\n",
        "    \n",
        "    def relu(self, value, derivative = False):\n",
        "        \"\"\"\n",
        "        This is the Rectified Linear Unit (ReLU) activation function which can be \n",
        "        used in computing the activation of a neuron. This function returns a value \n",
        "        of 0 if it is fed a value less than 0 and returns the value it was fed if \n",
        "        the value is greater than 0. It can also be used as the derivative of the \n",
        "        relu function (which again we will need in backpropagation).\n",
        "        \"\"\"\n",
        "        if derivative:\n",
        "            return 1 if value > 0 else 0\n",
        "        return value if value > 0 else 0\n",
        "    \n",
        "    def activate(self, inputs, weights, bias, activation):\n",
        "        \"\"\"\n",
        "        This function computes the activation of a specific neuron. It computes\n",
        "        the dot product of the input and weight vectors (basically just multiplying\n",
        "        all of the weights coming into the neuron with the corresponding outputs\n",
        "        of the neurons they are coming from and then adding all of them up) and \n",
        "        then adds the bias to this number before passing the whole sum into the\n",
        "        specified activation function.\n",
        "        \"\"\"\n",
        "        activation_functions = {'sigmoid': self.sigmoid, 'relu': self.relu}\n",
        "        activation_function = activation_functions[activation]\n",
        "        \n",
        "        return activation_function(sum([inputs[i] * weights[i] for i in range(len(inputs))]) + bias)\n",
        "    \n",
        "    def forward_propagate(self, inputs):\n",
        "        \"\"\"\n",
        "        This function passes the specified inputs into the input layer of the neural\n",
        "        network. From there, it computes the activation of each neuron in a layer \n",
        "        using the fuction above and then passes these activations to the neurons\n",
        "        of the next layer, repeating this process until it reaches the output layer.\n",
        "        \"\"\"\n",
        "        for layer in self.neural_network:\n",
        "            layer_outputs = list()\n",
        "            for neuron in layer:\n",
        "                #Here we store the outputs of each neuron (computed using the activate\n",
        "                #function we defined above) because we will need them for backpropagation\n",
        "                neuron['output'] = self.activate(inputs, neuron['weights'], neuron['bias'], neuron['activation'])\n",
        "                layer_outputs.append(neuron['output'])\n",
        "            #Here is where we pass the outputs of one layer as the inputs of the next layer\n",
        "            inputs = layer_outputs\n",
        "        #Here we return the output of the final layer (which is the prediction of the network)\n",
        "        return inputs\n",
        "    \n",
        "    # Section 3: Backward Propagation\n",
        "    def backward_propagate(self, inputs, expected_outputs, learning_rate):\n",
        "        \"\"\"\n",
        "        This function calculates the error of our network (the difference between\n",
        "        the output predicted by the network and the output it was supposed to predict).\n",
        "        In then uses this error of the last neurons in the network to calculate the \n",
        "        error of the neurons in the previous layer using some simple calculus. \n",
        "        Then, it adjust the weights and biases of our neural network based on the\n",
        "        errors of each neuron (this is what actually makes the network more accurate).\n",
        "        \"\"\"\n",
        "        #Here, we compute the errors of each neuron, focusing on the layers\n",
        "        #In reverse order where we start by looking at the last layer\n",
        "        for i in reversed(range(len(self.neural_network))):\n",
        "            layer = self.neural_network[i]\n",
        "            layer_errors = list()\n",
        "            #If we are looking at the last layer...\n",
        "            if i == len(self.neural_network) - 1:\n",
        "                for j in range(len(layer)):\n",
        "                    neuron = layer[j]\n",
        "                    #Compute the error of the output neurons in our neural network\n",
        "                    neuron_error = expected_outputs[j] - neuron['output']\n",
        "                    layer_errors.append(neuron_error)\n",
        "            else:\n",
        "                #For any other layer besides the last layer...\n",
        "                for j in range(len(layer)):\n",
        "                    #Calculate the error associated with each neuron based on the \n",
        "                    #connected neurons in the following layer\n",
        "                    neuron_error = sum([neuron['weights'][j] * neuron['error'] for neuron in self.neural_network[i + 1]])\n",
        "                    layer_errors.append(neuron_error)\n",
        "            for j in range(len(layer)):\n",
        "                neuron = layer[j]\n",
        "                #Finally, multiply the errors we found before by the derivative of \n",
        "                #activation function of each neuron (this comes from using the chain\n",
        "                #rule from calculus).\n",
        "                neuron['error'] = layer_errors[j] * self.sigmoid(neuron['output'], True)\n",
        "        \n",
        "        #Here, we adjust the weights of our network based on the errors we computed\n",
        "        #This time we go through the neural network in order from the first to last layer\n",
        "        for i in range(len(self.neural_network)):\n",
        "            layer = self.neural_network[i]\n",
        "            for neuron in layer:\n",
        "                for j in range(len(neuron['weights'])):\n",
        "                    #Here we adjust the weights based on the error associated with\n",
        "                    #each neuron and the outputs of the previous layer. We also\n",
        "                    #take into account the learning rate to specify how much we want\n",
        "                    #to adjust our weights for each training example.\n",
        "                    neuron['weights'][j] += learning_rate * inputs[j] * neuron['error']\n",
        "                #Here we adjust the bias taking into account the learning rate\n",
        "                neuron['bias'] += learning_rate * neuron['error']\n",
        "            #Here we save the outputs of the current layer so that we can reference them\n",
        "            #When adjusting the weights of the next layer.\n",
        "            inputs = [neuron['output'] for neuron in self.neural_network[i]]\n",
        "    \n",
        "    #Section 4: Training\n",
        "    def train(self, x_train, y_train, learning_rate, epochs):\n",
        "        \"\"\"\n",
        "        Finally, we create the method which we wil use to access all of the above\n",
        "        methods. This method will allow us to pass in training data into our neural\n",
        "        network. The network will train with the specified number of epochs (iterations\n",
        "        through the training data) and will use the specified learning rate.\n",
        "        \n",
        "        \"\"\"\n",
        "        for epoch in range(epochs):\n",
        "            total_error = 0\n",
        "            for i in range(len(x_train)):\n",
        "                x = x_train[i]\n",
        "                y = y_train[i]\n",
        "                #Propagate our training inputs through our network\n",
        "                outputs = self.forward_propagate(x)\n",
        "                #Calculate the mean squared error of the predicted outputs (for display purposes)\n",
        "                total_error += sum([(y[j] - outputs[j]) ** 2 for j in range(len(outputs))])\n",
        "                #Adjust weights and biases with backpropagation\n",
        "                self.backward_propagate(x, y, learning_rate)\n",
        "            #Print a message to the console at the end of each epoch so we can see\n",
        "            #The progress of the neural network/if it is improving\n",
        "            print(\"Epoch: {}, Total Error: {:.3f}\".format(epoch + 1, total_error))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk-FNvk7m89T"
      },
      "source": [
        "**Making a Prediction Function**\n",
        "\n",
        "This function allows us to assess the accuracy of our model once it is already trained. It tests the models predictions for specific values against what the actual values are and returns the number of correct and incorrect answers that the model provided. This will serve as a way for us to adress if our model is working properly later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UzyCow4skbT"
      },
      "source": [
        "def predict(model, x_test, y_test):\n",
        "    num_correct = 0\n",
        "    num_wrong = 0\n",
        "    for i in range(len(x_test)):\n",
        "        x = x_test[i]\n",
        "        y = y_test[i]\n",
        "        outputs = model.forward_propagate(x)\n",
        "        outputs = 1 if outputs[0] > .5 else 0 \n",
        "        if outputs == y[0]:\n",
        "            num_correct += 1\n",
        "        else:\n",
        "            num_wrong += 1\n",
        "    print(\"Correct: {}, Incorrect: {}, Accuracy: {}\".format(num_correct, num_wrong, num_correct/(num_correct + num_wrong)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HKUx2RtmYng"
      },
      "source": [
        "# **The Dataset**\n",
        "Here is the dataset we will be using: [Bank Customer Data Spreadsheet](https://drive.google.com/file/d/0B6eU_Ir83rAKOVdxV0MzazdNQlE1TXJNNDJOS2lDaFFYMkww/view?usp=sharing)\n",
        "\n",
        "***If you want to follow along and run the code below, click on the dataset above and hit the download button in the top right.***\n",
        "\n",
        "You can see that in the left columns, there is data about each customer. The farthest right column stores a value of 1 if the customer ended up staying with the bank after six months and 0 if the customer decided to leave.\n",
        "\n",
        "At the end of the project, our goal is to have a program that predicts if customers will stay with a bank in the next six months based on statistics about the customer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-2jcQSDnsDX"
      },
      "source": [
        "**Upload the Dataset to Python**\n",
        "\n",
        "\n",
        "1.   Run the below code and click the \"Choose Files\" button that appears\n",
        "2.   Select the \"Bank_Customer_Data.csv\" file from your file explorer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj5tbS0uxx6Q"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqYsTK0w61OP"
      },
      "source": [
        "\n",
        "3.    Wait until the dataset is 100% done loading\n",
        "3.    Now run the below code and the dataset is ready to go!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBdQLPlIVrf-"
      },
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"Bank_Customer_Data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H1qcH-UCdp2"
      },
      "source": [
        "5.     If you run the following code, you can see what five rows of the dataset look like. You can adjust the numbers in the brackets to see more of the dataset. If you make the brackets look like this then you will be able to see the entire dataset: ```[:, :]```. Note that you can't see the middle columns of the table just because there are too many columns to display so they are abbreviated with elipses. The columns are still in the actual dataset though.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ViFhwvCdBH"
      },
      "source": [
        "print(dataset.iloc[1:6, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs6DxIWkn2iU"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhL-BvVQoHNR"
      },
      "source": [
        "In this stage, we clean the data in our dataset and prepare it to be passed through our neural network. For the sake of being concise and avoiding redundancy, I won't describe every detail of what is going on here but if you want to learn more about the specifics of this code, check out my [original Python notebook](https://colab.research.google.com/drive/1stLWnNExen8nat0gEdQbnEgCeZ3UdGnO?usp=sharing) on this code where I explain it all.\n",
        "\n",
        "**Run the code below to preprocess the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz9vEH3GBc5H"
      },
      "source": [
        "# Importing numpy\n",
        "import numpy as np\n",
        "\n",
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values\n",
        "\n",
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#This code was changed because the one hot encoder API changed\n",
        "label_encoder_x_1 = LabelEncoder()\n",
        "X[: , 2] = label_encoder_x_1.fit_transform(X[:,2])\n",
        "transformer = ColumnTransformer(transformers = [(\"OneHot\", OneHotEncoder(), [1])], remainder ='passthrough') \n",
        "\n",
        "X = transformer.fit_transform(X.tolist())\n",
        "X = X.astype('float64')\n",
        "X = X[:, 1:]\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsKu-B3rolF0"
      },
      "source": [
        "Currently all of our data is arranged into a numpy array. However, the neural network engine we build takes data in the form of standard Python arrays (which can have many dimensions). Thus, we will need to convert these numpy arrays to traditional Python arrays with the following code so that we can pass them into our custom neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpTIBg0Ol8ud"
      },
      "source": [
        "x_train = []\n",
        "for row in X_train:\n",
        "    x_train.append([item for item in row])\n",
        "\n",
        "x_test = []\n",
        "for row in X_test:\n",
        "    x_test.append([item for item in row])\n",
        "\n",
        "y_train = []\n",
        "for item in Y_train:\n",
        "    y_train.append([item])\n",
        "    \n",
        "y_test = []\n",
        "for item in Y_test:\n",
        "    y_test.append([item])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DAkDEN3pQo5"
      },
      "source": [
        "# **Building The Neural Network**\n",
        "\n",
        "Now that all of the data is processed properly, we can get to creating the actual neural network. We are trying to create a neural network that will take in all of the input data about the banks customers (there are 11 datapoints for each customer in the dataset) and will make a prediction as to whether they will remain with or leave the bank in the next six months. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXrc-0C7l-7S"
      },
      "source": [
        "#Create an instance of our NeuralNetwork class\n",
        "model = NeuralNetwork()\n",
        "\n",
        "#Since we have 11 datapoints about each customer, we will need an input layer with 11 inputs neurons\n",
        "model.add_layer(11, input_layer = True)\n",
        "\n",
        "#A common rule for the number of neurons in the hidden layers is to take the average of the neurons\n",
        "#In the input and output layers, which in this case is 6\n",
        "model.add_layer(6, activation = 'sigmoid')\n",
        "model.add_layer(6, activation = 'sigmoid')\n",
        "\n",
        "#Finally, we want to predict a single binary value so we only need one neuron in the output layer\n",
        "model.add_layer(1, activation = 'sigmoid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMRbm3QHqqVx"
      },
      "source": [
        "Now that the neural network is build, we can train the network to see how accurate it is at making predictions for this problem. When you run the code below, you will see that the neural network is training properly as the error is steadily decreasing with each new batch of training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIx2LpBkp5Qr"
      },
      "source": [
        "model.train(x_train, y_train, 0.3, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOo2Ww8UrDgj"
      },
      "source": [
        "Finally, we can use our model to make predictions about customers that it is has not analyzed yet (this data is coming from the testing datasets we created in the data preprocessing stage). Run the code below to see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VFTYCnNrRLP"
      },
      "source": [
        "predict(model, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qog3Aub5rSQ0"
      },
      "source": [
        "As you can see, the model is working very well! It usually gets to around an 85-86% accuracy level with its predictions. If you saw [my Python notebook](https://colab.research.google.com/drive/1stLWnNExen8nat0gEdQbnEgCeZ3UdGnO?usp=sharing/) where I used keras to solve this exact problem, the neural network usually got to an accuracy level of about 85%. This means that the neural network that we built completely from scratch is almost as good if not slightly better than keras, one of the industry standards for building neural networks! Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-XeRS1bu6Of"
      },
      "source": [
        "# **Thanks for Reading!**\n",
        "\n",
        "My name is Adam Majmudar and I'm a 17 year old machine learning developer.\n",
        "\n",
        "If you want to connect with me/see my work, check out the following links:\n",
        "\n",
        "* [My Medium](https://medium.com/@mr.adam.maj)\n",
        "* [My Linkedin](https://www.linkedin.com/in/adam-majmudar-24b596194/)\n",
        "* [My Portfolio](https://tks.life/profile/adam.majmudar)"
      ]
    }
  ]
}